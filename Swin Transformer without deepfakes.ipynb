{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-24T05:41:46.122082Z","iopub.execute_input":"2022-07-24T05:41:46.123055Z","iopub.status.idle":"2022-07-24T05:42:14.060005Z","shell.execute_reply.started":"2022-07-24T05:41:46.122951Z","shell.execute_reply":"2022-07-24T05:42:14.058878Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport pandas as pd\nimport time\nimport glob\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport os\nimport PIL\nimport cv2\nimport shutil\nfrom sklearn.metrics import confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:35.910364Z","iopub.execute_input":"2022-07-24T09:17:35.910938Z","iopub.status.idle":"2022-07-24T09:17:36.518637Z","shell.execute_reply.started":"2022-07-24T09:17:35.910898Z","shell.execute_reply":"2022-07-24T09:17:36.517451Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:36.520909Z","iopub.execute_input":"2022-07-24T09:17:36.521592Z","iopub.status.idle":"2022-07-24T09:17:37.430480Z","shell.execute_reply.started":"2022-07-24T09:17:36.521549Z","shell.execute_reply":"2022-07-24T09:17:37.429248Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/covidx-cxr2/train.txt', sep=\" \", header=None)\ntrain_df.columns=['patient id', 'file_paths', 'labels', 'data source']\ntrain_df=train_df.drop(['patient id', 'data source'], axis=1 )","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:37.435787Z","iopub.execute_input":"2022-07-24T09:17:37.438171Z","iopub.status.idle":"2022-07-24T09:17:37.555431Z","shell.execute_reply.started":"2022-07-24T09:17:37.438129Z","shell.execute_reply":"2022-07-24T09:17:37.554282Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:37.557833Z","iopub.execute_input":"2022-07-24T09:17:37.558509Z","iopub.status.idle":"2022-07-24T09:17:37.578372Z","shell.execute_reply.started":"2022-07-24T09:17:37.558470Z","shell.execute_reply":"2022-07-24T09:17:37.577469Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/covidx-cxr2/test.txt', sep=\" \", header=None)\ntest_df.columns=['id', 'file_paths', 'labels', 'data source' ]\ntest_df=test_df.drop(['id', 'data source'], axis=1 )","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:37.579843Z","iopub.execute_input":"2022-07-24T09:17:37.580405Z","iopub.status.idle":"2022-07-24T09:17:37.631434Z","shell.execute_reply.started":"2022-07-24T09:17:37.580352Z","shell.execute_reply":"2022-07-24T09:17:37.630535Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:37.640780Z","iopub.execute_input":"2022-07-24T09:17:37.641094Z","iopub.status.idle":"2022-07-24T09:17:37.653032Z","shell.execute_reply.started":"2022-07-24T09:17:37.641062Z","shell.execute_reply":"2022-07-24T09:17:37.652145Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/covidx-cxr2/train/'\ntest_path = '../input/covidx-cxr2/test/'","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:37.919268Z","iopub.execute_input":"2022-07-24T09:17:37.919730Z","iopub.status.idle":"2022-07-24T09:17:37.924762Z","shell.execute_reply.started":"2022-07-24T09:17:37.919691Z","shell.execute_reply":"2022-07-24T09:17:37.923749Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_df['labels'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:38.147341Z","iopub.execute_input":"2022-07-24T09:17:38.148658Z","iopub.status.idle":"2022-07-24T09:17:38.172185Z","shell.execute_reply.started":"2022-07-24T09:17:38.148613Z","shell.execute_reply":"2022-07-24T09:17:38.171286Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"file_count = 13000\nsamples = []\nfor category in train_df['labels'].unique():    \n    category_slice = train_df.query(\"labels == @category\")    \n    samples.append(category_slice.sample(file_count, replace=False,random_state=1))\ntrain_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\nprint ( train_df['labels'].value_counts())\nprint (len(train_df))","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:38.518797Z","iopub.execute_input":"2022-07-24T09:17:38.519211Z","iopub.status.idle":"2022-07-24T09:17:38.567579Z","shell.execute_reply.started":"2022-07-24T09:17:38.519174Z","shell.execute_reply":"2022-07-24T09:17:38.566655Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"train_df, valid_df = train_test_split(train_df, train_size=0.9, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:38.844465Z","iopub.execute_input":"2022-07-24T09:17:38.847286Z","iopub.status.idle":"2022-07-24T09:17:38.861049Z","shell.execute_reply.started":"2022-07-24T09:17:38.847245Z","shell.execute_reply":"2022-07-24T09:17:38.859682Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"print(train_df.labels.value_counts())\nprint(valid_df.labels.value_counts())\nprint(test_df.labels.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:17:39.159192Z","iopub.execute_input":"2022-07-24T09:17:39.160030Z","iopub.status.idle":"2022-07-24T09:17:39.201130Z","shell.execute_reply.started":"2022-07-24T09:17:39.159961Z","shell.execute_reply":"2022-07-24T09:17:39.200126Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"target_size=(224, 224)\nbatch_size=64","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:25:27.909138Z","iopub.execute_input":"2022-07-24T09:25:27.909573Z","iopub.status.idle":"2022-07-24T09:25:27.914530Z","shell.execute_reply.started":"2022-07-24T09:25:27.909540Z","shell.execute_reply":"2022-07-24T09:25:27.913451Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n    horizontal_flip=True, zoom_range=0.1\n)\n\ntest_datagen = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input\n)\n\ntrain_gen = train_datagen.flow_from_dataframe(\n    train_df,\n    directory=train_path,\n    x_col='file_paths',\n    y_col='labels',\n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',\n    class_mode='binary'\n)\n\n\nvalid_gen = test_datagen.flow_from_dataframe(\n    valid_df,\n    directory=train_path,\n    x_col='file_paths',\n    y_col='labels', \n    target_size=target_size,\n    batch_size=batch_size,\n    color_mode='rgb',\n    class_mode='binary'\n)\n\ntest_gen = test_datagen.flow_from_dataframe(\n    test_df,\n    directory=test_path,\n    x_col='file_paths',\n    y_col='labels',\n    target_size=target_size,\n    batch_size=batch_size, \n    color_mode='rgb',\n    class_mode='binary'\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:25:28.305387Z","iopub.execute_input":"2022-07-24T09:25:28.306236Z","iopub.status.idle":"2022-07-24T09:25:38.712456Z","shell.execute_reply.started":"2022-07-24T09:25:28.306190Z","shell.execute_reply":"2022-07-24T09:25:38.711367Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:25:38.714433Z","iopub.execute_input":"2022-07-24T09:25:38.714763Z","iopub.status.idle":"2022-07-24T09:25:38.719557Z","shell.execute_reply.started":"2022-07-24T09:25:38.714727Z","shell.execute_reply":"2022-07-24T09:25:38.718610Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"num_classes = 2\ninput_shape = (224, 224, 3)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:25:40.113058Z","iopub.execute_input":"2022-07-24T09:25:40.113627Z","iopub.status.idle":"2022-07-24T09:25:40.118334Z","shell.execute_reply.started":"2022-07-24T09:25:40.113590Z","shell.execute_reply":"2022-07-24T09:25:40.117396Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"patch_size = (2, 2)  # 2-by-2 sized patches\ndropout_rate = 0.03  # Dropout rate\nnum_heads = 8  # Attention heads\nembed_dim = 64  # Embedding dimension\nnum_mlp = 256  # MLP layer size\nqkv_bias = True  # Convert embedded patches to query, key, and values with a learnable additive value\nwindow_size = 2  # Size of attention window\nshift_size = 1  # Size of shifting window\nimage_dimension = 224  # Initial image size\n\nnum_patch_x = input_shape[0] // patch_size[0]\nnum_patch_y = input_shape[1] // patch_size[1]\n\nlearning_rate = 1e-3\nbatch_size = 128\nnum_epochs = 40\nvalidation_split = 0.1\nweight_decay = 0.0001\nlabel_smoothing = 0.1","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:25:51.283426Z","iopub.execute_input":"2022-07-24T09:25:51.284009Z","iopub.status.idle":"2022-07-24T09:25:51.291342Z","shell.execute_reply.started":"2022-07-24T09:25:51.283972Z","shell.execute_reply":"2022-07-24T09:25:51.290135Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"def window_partition(x, window_size):\n    _, height, width, channels = x.shape\n    patch_num_y = height // window_size\n    patch_num_x = width // window_size\n    x = tf.reshape(\n        x, shape=(-1, patch_num_y, window_size, patch_num_x, window_size, channels)\n    )\n    x = tf.transpose(x, (0, 1, 3, 2, 4, 5))\n    windows = tf.reshape(x, shape=(-1, window_size, window_size, channels))\n    return windows\n\n\ndef window_reverse(windows, window_size, height, width, channels):\n    patch_num_y = height // window_size\n    patch_num_x = width // window_size\n    x = tf.reshape(\n        windows,\n        shape=(-1, patch_num_y, patch_num_x, window_size, window_size, channels),\n    )\n    x = tf.transpose(x, perm=(0, 1, 3, 2, 4, 5))\n    x = tf.reshape(x, shape=(-1, height, width, channels))\n    return x\n\n\nclass DropPath(layers.Layer):\n    def __init__(self, drop_prob=None, **kwargs):\n        super(DropPath, self).__init__(**kwargs)\n        self.drop_prob = drop_prob\n\n    def call(self, x):\n        input_shape = tf.shape(x)\n        batch_size = input_shape[0]\n        rank = x.shape.rank\n        shape = (batch_size,) + (1,) * (rank - 1)\n        random_tensor = (1 - self.drop_prob) + tf.random.uniform(shape, dtype=x.dtype)\n        path_mask = tf.floor(random_tensor)\n        output = tf.math.divide(x, 1 - self.drop_prob) * path_mask\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:25:52.289602Z","iopub.execute_input":"2022-07-24T09:25:52.290047Z","iopub.status.idle":"2022-07-24T09:25:52.313015Z","shell.execute_reply.started":"2022-07-24T09:25:52.290009Z","shell.execute_reply":"2022-07-24T09:25:52.311870Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"class WindowAttention(layers.Layer):\n    def __init__(\n        self, dim, window_size, num_heads, qkv_bias=True, dropout_rate=0.0, **kwargs\n    ):\n        super(WindowAttention, self).__init__(**kwargs)\n        self.dim = dim\n        self.window_size = window_size\n        self.num_heads = num_heads\n        self.scale = (dim // num_heads) ** -0.5\n        self.qkv = layers.Dense(dim * 3, use_bias=qkv_bias)\n        self.dropout = layers.Dropout(dropout_rate)\n        self.proj = layers.Dense(dim)\n\n    def build(self, input_shape):\n        num_window_elements = (2 * self.window_size[0] - 1) * (\n            2 * self.window_size[1] - 1\n        )\n        self.relative_position_bias_table = self.add_weight(\n            shape=(num_window_elements, self.num_heads),\n            initializer=tf.initializers.Zeros(),\n            trainable=True,\n        )\n        coords_h = np.arange(self.window_size[0])\n        coords_w = np.arange(self.window_size[1])\n        coords_matrix = np.meshgrid(coords_h, coords_w, indexing=\"ij\")\n        coords = np.stack(coords_matrix)\n        coords_flatten = coords.reshape(2, -1)\n        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n        relative_coords = relative_coords.transpose([1, 2, 0])\n        relative_coords[:, :, 0] += self.window_size[0] - 1\n        relative_coords[:, :, 1] += self.window_size[1] - 1\n        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n        relative_position_index = relative_coords.sum(-1)\n\n        self.relative_position_index = tf.Variable(\n            initial_value=tf.convert_to_tensor(relative_position_index), trainable=False\n        )\n\n    def call(self, x, mask=None):\n        _, size, channels = x.shape\n        head_dim = channels // self.num_heads\n        x_qkv = self.qkv(x)\n        x_qkv = tf.reshape(x_qkv, shape=(-1, size, 3, self.num_heads, head_dim))\n        x_qkv = tf.transpose(x_qkv, perm=(2, 0, 3, 1, 4))\n        q, k, v = x_qkv[0], x_qkv[1], x_qkv[2]\n        q = q * self.scale\n        k = tf.transpose(k, perm=(0, 1, 3, 2))\n        attn = q @ k\n\n        num_window_elements = self.window_size[0] * self.window_size[1]\n        relative_position_index_flat = tf.reshape(\n            self.relative_position_index, shape=(-1,)\n        )\n        relative_position_bias = tf.gather(\n            self.relative_position_bias_table, relative_position_index_flat\n        )\n        relative_position_bias = tf.reshape(\n            relative_position_bias, shape=(num_window_elements, num_window_elements, -1)\n        )\n        relative_position_bias = tf.transpose(relative_position_bias, perm=(2, 0, 1))\n        attn = attn + tf.expand_dims(relative_position_bias, axis=0)\n\n        if mask is not None:\n            nW = mask.get_shape()[0]\n            mask_float = tf.cast(\n                tf.expand_dims(tf.expand_dims(mask, axis=1), axis=0), tf.float32\n            )\n            attn = (\n                tf.reshape(attn, shape=(-1, nW, self.num_heads, size, size))\n                + mask_float\n            )\n            attn = tf.reshape(attn, shape=(-1, self.num_heads, size, size))\n            attn = keras.activations.softmax(attn, axis=-1)\n        else:\n            attn = keras.activations.softmax(attn, axis=-1)\n        attn = self.dropout(attn)\n\n        x_qkv = attn @ v\n        x_qkv = tf.transpose(x_qkv, perm=(0, 2, 1, 3))\n        x_qkv = tf.reshape(x_qkv, shape=(-1, size, channels))\n        x_qkv = self.proj(x_qkv)\n        x_qkv = self.dropout(x_qkv)\n        return x_qkv","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:25:52.608244Z","iopub.execute_input":"2022-07-24T09:25:52.608718Z","iopub.status.idle":"2022-07-24T09:25:52.640666Z","shell.execute_reply.started":"2022-07-24T09:25:52.608677Z","shell.execute_reply":"2022-07-24T09:25:52.639561Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"class SwinTransformer(layers.Layer):\n    def __init__(\n        self,\n        dim,\n        num_patch,\n        num_heads,\n        window_size=7,\n        shift_size=0,\n        num_mlp=1024,\n        qkv_bias=True,\n        dropout_rate=0.0,\n        **kwargs,\n    ):\n        super(SwinTransformer, self).__init__(**kwargs)\n\n        self.dim = dim  # number of input dimensions\n        self.num_patch = num_patch  # number of embedded patches\n        self.num_heads = num_heads  # number of attention heads\n        self.window_size = window_size  # size of window\n        self.shift_size = shift_size  # size of window shift\n        self.num_mlp = num_mlp  # number of MLP nodes\n\n        self.norm1 = layers.LayerNormalization(epsilon=1e-5)\n        self.attn = WindowAttention(\n            dim,\n            window_size=(self.window_size, self.window_size),\n            num_heads=num_heads,\n            qkv_bias=qkv_bias,\n            dropout_rate=dropout_rate,\n        )\n        self.drop_path = DropPath(dropout_rate)\n        self.norm2 = layers.LayerNormalization(epsilon=1e-5)\n\n        self.mlp = keras.Sequential(\n            [\n                layers.Dense(num_mlp),\n                layers.Activation(keras.activations.gelu),\n                layers.Dropout(dropout_rate),\n                layers.Dense(dim),\n                layers.Dropout(dropout_rate),\n            ]\n        )\n\n        if min(self.num_patch) < self.window_size:\n            self.shift_size = 0\n            self.window_size = min(self.num_patch)\n\n    def build(self, input_shape):\n        if self.shift_size == 0:\n            self.attn_mask = None\n        else:\n            height, width = self.num_patch\n            h_slices = (\n                slice(0, -self.window_size),\n                slice(-self.window_size, -self.shift_size),\n                slice(-self.shift_size, None),\n            )\n            w_slices = (\n                slice(0, -self.window_size),\n                slice(-self.window_size, -self.shift_size),\n                slice(-self.shift_size, None),\n            )\n            mask_array = np.zeros((1, height, width, 1))\n            count = 0\n            for h in h_slices:\n                for w in w_slices:\n                    mask_array[:, h, w, :] = count\n                    count += 1\n            mask_array = tf.convert_to_tensor(mask_array)\n\n            # mask array to windows\n            mask_windows = window_partition(mask_array, self.window_size)\n            mask_windows = tf.reshape(\n                mask_windows, shape=[-1, self.window_size * self.window_size]\n            )\n            attn_mask = tf.expand_dims(mask_windows, axis=1) - tf.expand_dims(\n                mask_windows, axis=2\n            )\n            attn_mask = tf.where(attn_mask != 0, -100.0, attn_mask)\n            attn_mask = tf.where(attn_mask == 0, 0.0, attn_mask)\n            self.attn_mask = tf.Variable(initial_value=attn_mask, trainable=False)\n\n    def call(self, x):\n        height, width = self.num_patch\n        _, num_patches_before, channels = x.shape\n        x_skip = x\n        x = self.norm1(x)\n        x = tf.reshape(x, shape=(-1, height, width, channels))\n        if self.shift_size > 0:\n            shifted_x = tf.roll(\n                x, shift=[-self.shift_size, -self.shift_size], axis=[1, 2]\n            )\n        else:\n            shifted_x = x\n\n        x_windows = window_partition(shifted_x, self.window_size)\n        x_windows = tf.reshape(\n            x_windows, shape=(-1, self.window_size * self.window_size, channels)\n        )\n        attn_windows = self.attn(x_windows, mask=self.attn_mask)\n\n        attn_windows = tf.reshape(\n            attn_windows, shape=(-1, self.window_size, self.window_size, channels)\n        )\n        shifted_x = window_reverse(\n            attn_windows, self.window_size, height, width, channels\n        )\n        if self.shift_size > 0:\n            x = tf.roll(\n                shifted_x, shift=[self.shift_size, self.shift_size], axis=[1, 2]\n            )\n        else:\n            x = shifted_x\n\n        x = tf.reshape(x, shape=(-1, height * width, channels))\n        x = self.drop_path(x)\n        x = x_skip + x\n        x_skip = x\n        x = self.norm2(x)\n        x = self.mlp(x)\n        x = self.drop_path(x)\n        x = x_skip + x\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:25:53.013711Z","iopub.execute_input":"2022-07-24T09:25:53.014259Z","iopub.status.idle":"2022-07-24T09:25:53.055215Z","shell.execute_reply.started":"2022-07-24T09:25:53.014228Z","shell.execute_reply":"2022-07-24T09:25:53.054092Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"class PatchExtract(layers.Layer):\n    def __init__(self, patch_size, **kwargs):\n        super(PatchExtract, self).__init__(**kwargs)\n        self.patch_size_x = patch_size[0]\n        self.patch_size_y = patch_size[0]\n\n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=(1, self.patch_size_x, self.patch_size_y, 1),\n            strides=(1, self.patch_size_x, self.patch_size_y, 1),\n            rates=(1, 1, 1, 1),\n            padding=\"VALID\",\n        )\n        patch_dim = patches.shape[-1]\n        patch_num = patches.shape[1]\n        return tf.reshape(patches, (batch_size, patch_num * patch_num, patch_dim))\n\n\nclass PatchEmbedding(layers.Layer):\n    def __init__(self, num_patch, embed_dim, **kwargs):\n        super(PatchEmbedding, self).__init__(**kwargs)\n        self.num_patch = num_patch\n        self.proj = layers.Dense(embed_dim)\n        self.pos_embed = layers.Embedding(input_dim=num_patch, output_dim=embed_dim)\n\n    def call(self, patch):\n        pos = tf.range(start=0, limit=self.num_patch, delta=1)\n        return self.proj(patch) + self.pos_embed(pos)\n\n\nclass PatchMerging(tf.keras.layers.Layer):\n    def __init__(self, num_patch, embed_dim):\n        super(PatchMerging, self).__init__()\n        self.num_patch = num_patch\n        self.embed_dim = embed_dim\n        self.linear_trans = layers.Dense(2 * embed_dim, use_bias=False)\n\n    def call(self, x):\n        height, width = self.num_patch\n        _, _, C = x.get_shape().as_list()\n        x = tf.reshape(x, shape=(-1, height, width, C))\n        x0 = x[:, 0::2, 0::2, :]\n        x1 = x[:, 1::2, 0::2, :]\n        x2 = x[:, 0::2, 1::2, :]\n        x3 = x[:, 1::2, 1::2, :]\n        x = tf.concat((x0, x1, x2, x3), axis=-1)\n        x = tf.reshape(x, shape=(-1, (height // 2) * (width // 2), 4 * C))\n        return self.linear_trans(x)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:25:53.327213Z","iopub.execute_input":"2022-07-24T09:25:53.327584Z","iopub.status.idle":"2022-07-24T09:25:53.343958Z","shell.execute_reply.started":"2022-07-24T09:25:53.327554Z","shell.execute_reply":"2022-07-24T09:25:53.342962Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"input = layers.Input(input_shape)\nx = layers.RandomCrop(image_dimension, image_dimension)(input)\nx = layers.RandomFlip(\"horizontal\")(x)\nx = PatchExtract(patch_size)(x)\nx = PatchEmbedding(num_patch_x * num_patch_y, embed_dim)(x)\nx = SwinTransformer(\n    dim=embed_dim,\n    num_patch=(num_patch_x, num_patch_y),\n    num_heads=num_heads,\n    window_size=window_size,\n    shift_size=0,\n    num_mlp=num_mlp,\n    qkv_bias=qkv_bias,\n    dropout_rate=dropout_rate,\n)(x)\nx = SwinTransformer(\n    dim=embed_dim,\n    num_patch=(num_patch_x, num_patch_y),\n    num_heads=num_heads,\n    window_size=window_size,\n    shift_size=shift_size,\n    num_mlp=num_mlp,\n    qkv_bias=qkv_bias,\n    dropout_rate=dropout_rate,\n)(x)\nx = PatchMerging((num_patch_x, num_patch_y), embed_dim=embed_dim)(x)\nx = layers.GlobalAveragePooling1D()(x)\noutput = layers.Dense(2, activation=\"softmax\")(x)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:26:51.863585Z","iopub.execute_input":"2022-07-24T09:26:51.864255Z","iopub.status.idle":"2022-07-24T09:26:52.527719Z","shell.execute_reply.started":"2022-07-24T09:26:51.864216Z","shell.execute_reply":"2022-07-24T09:26:52.526674Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"model = keras.Model(input, output)\nmodel.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(),\n    optimizer=tfa.optimizers.AdamW(\n        learning_rate=learning_rate, weight_decay=weight_decay\n    ),\n    metrics=[\n        keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n    ],\n)\n\nhistory = model.fit(\n    train_gen,\n    batch_size=batch_size,\n    epochs=num_epochs,\n    validation_data=valid_gen,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T09:27:21.256190Z","iopub.execute_input":"2022-07-24T09:27:21.256565Z","iopub.status.idle":"2022-07-24T16:52:56.269223Z","shell.execute_reply.started":"2022-07-24T09:27:21.256534Z","shell.execute_reply":"2022-07-24T16:52:56.267183Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"model.save('./SWin_Transformer.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:56:26.410299Z","iopub.execute_input":"2022-07-24T16:56:26.411014Z","iopub.status.idle":"2022-07-24T16:56:26.450087Z","shell.execute_reply.started":"2022-07-24T16:56:26.410977Z","shell.execute_reply":"2022-07-24T16:56:26.448460Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.plot(history.history['loss'], label='Loss (training data)')\nplt.plot(history.history['val_loss'], label='Loss (validation data)')\nplt.title('Learning Curves')\nplt.ylabel('Loss / accuracy')\nplt.xlabel('epochs')\nplt.legend(['train_accuracy', 'validation_accuracy','train_loss', 'validation_loss'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:52:56.279564Z","iopub.execute_input":"2022-07-24T16:52:56.282439Z","iopub.status.idle":"2022-07-24T16:52:56.604442Z","shell.execute_reply.started":"2022-07-24T16:52:56.282386Z","shell.execute_reply":"2022-07-24T16:52:56.603431Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9,9))\n\nplt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='val loss')\nplt.plot(history.history['accuracy'], label='train accuracy')\nplt.plot(history.history['val_accuracy'], label='val accuracy')\nplt.title('Learning Curves')\nplt.ylabel('Loss / accuracy')\nplt.xlabel('epochs')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:12:21.642955Z","iopub.execute_input":"2022-07-24T17:12:21.643304Z","iopub.status.idle":"2022-07-24T17:12:22.065936Z","shell.execute_reply.started":"2022-07-24T17:12:21.643272Z","shell.execute_reply":"2022-07-24T17:12:22.064876Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"model.save_weights('./S_Transformer_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:56:42.326470Z","iopub.execute_input":"2022-07-24T16:56:42.327043Z","iopub.status.idle":"2022-07-24T16:56:42.408991Z","shell.execute_reply.started":"2022-07-24T16:56:42.327007Z","shell.execute_reply":"2022-07-24T16:56:42.407557Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(test_gen)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T16:56:58.514733Z","iopub.execute_input":"2022-07-24T16:56:58.515701Z","iopub.status.idle":"2022-07-24T16:57:37.790848Z","shell.execute_reply.started":"2022-07-24T16:56:58.515665Z","shell.execute_reply":"2022-07-24T16:57:37.789799Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"predict","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:00:18.893851Z","iopub.execute_input":"2022-07-24T17:00:18.894183Z","iopub.status.idle":"2022-07-24T17:00:18.921118Z","shell.execute_reply.started":"2022-07-24T17:00:18.894156Z","shell.execute_reply":"2022-07-24T17:00:18.920078Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"y_pred = predict.argmax(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:00:41.994046Z","iopub.execute_input":"2022-07-24T17:00:41.994514Z","iopub.status.idle":"2022-07-24T17:00:42.000993Z","shell.execute_reply.started":"2022-07-24T17:00:41.994470Z","shell.execute_reply":"2022-07-24T17:00:42.000028Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"y_pred","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:00:48.659678Z","iopub.execute_input":"2022-07-24T17:00:48.660329Z","iopub.status.idle":"2022-07-24T17:00:48.668427Z","shell.execute_reply.started":"2022-07-24T17:00:48.660293Z","shell.execute_reply":"2022-07-24T17:00:48.667301Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"test_gen.classes","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:01:02.606831Z","iopub.execute_input":"2022-07-24T17:01:02.607352Z","iopub.status.idle":"2022-07-24T17:01:02.634169Z","shell.execute_reply.started":"2022-07-24T17:01:02.607323Z","shell.execute_reply":"2022-07-24T17:01:02.633205Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nprint('Confusion Matrix')\nmat = confusion_matrix(test_gen.classes, y_pred)\nprint(mat)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:01:19.451438Z","iopub.execute_input":"2022-07-24T17:01:19.451912Z","iopub.status.idle":"2022-07-24T17:01:19.465011Z","shell.execute_reply.started":"2022-07-24T17:01:19.451872Z","shell.execute_reply":"2022-07-24T17:01:19.463913Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"record = model.evaluate(test_gen)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:02:16.735266Z","iopub.execute_input":"2022-07-24T17:02:16.735933Z","iopub.status.idle":"2022-07-24T17:02:38.828982Z","shell.execute_reply.started":"2022-07-24T17:02:16.735897Z","shell.execute_reply":"2022-07-24T17:02:38.828055Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(test_gen.classes, y_pred)\ntotal = sum(sum(cm))","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:03:18.541800Z","iopub.execute_input":"2022-07-24T17:03:18.542151Z","iopub.status.idle":"2022-07-24T17:03:18.549552Z","shell.execute_reply.started":"2022-07-24T17:03:18.542122Z","shell.execute_reply":"2022-07-24T17:03:18.548539Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"cm","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:03:45.067509Z","iopub.execute_input":"2022-07-24T17:03:45.068027Z","iopub.status.idle":"2022-07-24T17:03:45.079469Z","shell.execute_reply.started":"2022-07-24T17:03:45.067994Z","shell.execute_reply":"2022-07-24T17:03:45.078335Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# acc= (cm[0,0]+cm[1+1]) / total\n\nimport seaborn as sns\nsns.heatmap(cm, annot=True, fmt='g')\n\n# y - axis true labels - 89+111 = 200, 93+107 = 200","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:04:47.844736Z","iopub.execute_input":"2022-07-24T17:04:47.845116Z","iopub.status.idle":"2022-07-24T17:04:48.149737Z","shell.execute_reply.started":"2022-07-24T17:04:47.845084Z","shell.execute_reply":"2022-07-24T17:04:48.148394Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"test_gen.classes","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:08:06.057872Z","iopub.execute_input":"2022-07-24T17:08:06.058213Z","iopub.status.idle":"2022-07-24T17:08:06.080278Z","shell.execute_reply.started":"2022-07-24T17:08:06.058184Z","shell.execute_reply":"2022-07-24T17:08:06.079350Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ntl = arr = np.array(test_gen.classes)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:08:59.481790Z","iopub.execute_input":"2022-07-24T17:08:59.482272Z","iopub.status.idle":"2022-07-24T17:08:59.491806Z","shell.execute_reply.started":"2022-07-24T17:08:59.482230Z","shell.execute_reply":"2022-07-24T17:08:59.490701Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"unique, counts = np.unique(tl, return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:09:18.680094Z","iopub.execute_input":"2022-07-24T17:09:18.680560Z","iopub.status.idle":"2022-07-24T17:09:18.686387Z","shell.execute_reply.started":"2022-07-24T17:09:18.680526Z","shell.execute_reply":"2022-07-24T17:09:18.685362Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"dict(zip(unique, counts))","metadata":{"execution":{"iopub.status.busy":"2022-07-24T17:09:33.160139Z","iopub.execute_input":"2022-07-24T17:09:33.160523Z","iopub.status.idle":"2022-07-24T17:09:33.168057Z","shell.execute_reply.started":"2022-07-24T17:09:33.160490Z","shell.execute_reply":"2022-07-24T17:09:33.166997Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}